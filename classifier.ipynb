{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Image classification** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "import keras.layers as layers\n",
    "import numpy as np\n",
    "from keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "import joblib\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "path = './content/data'\n",
    "\n",
    "#For each class\n",
    "for c in [c for c in os.listdir(path)if c != \".ipynb_checkpoints\"]:\n",
    "\n",
    "    classPath = os.path.join(path,c)\n",
    "\n",
    "    for image_name in [i for i in os.listdir(classPath) if i !=  \".ipynb_checkpoints\"]:\n",
    "\n",
    "        image = cv2.imread(os.path.join(classPath,image_name))\n",
    "        image = cv2.resize(image, (256, 256))\n",
    "\n",
    "        x.append(image)\n",
    "        y.append(int(c))\n",
    "\n",
    "y = np.array(y)\n",
    "x = np.array(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(x,y,test_size=0.15,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augm = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "X_train = X_train.reshape((len(X_train), 256, 256, 3))\n",
    "augm.fit(X_train)\n",
    "augmented_data = augm.flow(X_train, Y_train, batch_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.asarray(Y_train).astype('float32').reshape((-1,1))\n",
    "Y_test = np.asarray(Y_test).astype('float32').reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Build neural network\n",
    "\n",
    "# Net \n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(3024, 4032, 3)))\n",
    "model.add(Dense(600, activation='relu'))\n",
    "model.add(Dense(600, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid')) #Output layer should be sigmoid for binary problems (0,1)\n",
    "\n",
    "# Optimizer setup\n",
    "model.compile(loss='binary_crossentropy',#Cost function\n",
    "              optimizer= SGD(learning_rate=0.01),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# Net training\n",
    "model_history = model.fit(X_train, Y_train,\n",
    "                          epochs=130, verbose=1,\n",
    "                          validation_data=(X_test, Y_test),\n",
    "                          callbacks=EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,(3,3),activation='relu',input_shape=(256,256,3)))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64,activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(augmented_data,epochs=100,verbose=1,batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getResults(threshold):\n",
    "  y_pred = (model.predict(X_test,verbose=0) > threshold).astype(int)\n",
    "  print('\\nThreshold: ', threshold)\n",
    "\n",
    "  print('Accuracy:',accuracy_score(Y_test, y_pred))\n",
    "  print('Precision:',precision_score(Y_test, y_pred))\n",
    "  print('Recall:',recall_score(Y_test, y_pred))\n",
    "  print('Confusion matrix',confusion_matrix(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for threshold in [.5,.6,.68]:\n",
    "  getResults(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def isMyDogInTheVideo(video_path,model,threshold):\n",
    "\n",
    "  #Reading video\n",
    "  video = cv2.VideoCapture(video_path)\n",
    "\n",
    "  #Getting video info\n",
    "  fps = video.get(cv2.CAP_PROP_FPS)\n",
    "  total_fps = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "  video_duration = total_fps / fps\n",
    "\n",
    "\n",
    "  #Getting the array of each frame and adding it to frames\n",
    "  frames = []\n",
    "  frame_num = 1\n",
    "  secs = []\n",
    "\n",
    "  while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.resize(frame, (256, 256))\n",
    "    frames.append(frame)\n",
    "    aug_frame = np.expand_dims(frame, axis=0)\n",
    "\n",
    "    #Predicting for each frame and showing the image\n",
    "    if model.predict(aug_frame,verbose=0)[0][0] > threshold:\n",
    "\n",
    "      sec = math.ceil(frame_num / fps)\n",
    "      secs.append(sec)\n",
    "\n",
    "      print(f'Lucas was seen in frame number {frame_num}, in second {sec} with a probability of {model.predict(aug_frame,verbose=0)[0][0]}')\n",
    "      plt.imshow(frame)\n",
    "      plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    frame_num += 1\n",
    "\n",
    "  #Getting secs where Lucas was seen\n",
    "  secs = list(set(secs))\n",
    "  print(f'Lucas appeared in seconds: {secs}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isMyDogInTheVideo('.path/test_video2.mp4',model,.70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
